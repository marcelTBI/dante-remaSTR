from __future__ import annotations

from datetime import datetime
from typing import TextIO, Iterable, Iterator, Any
from typing import List, Tuple
from typing import Optional
import argparse
import csv
import gzip
import io
import itertools
import multiprocessing
import re
import os
import sys
import textwrap
import logging

import numpy as np
import pandas as pd
import numpy.typing as npt

from src.inference import Inference, phase, save_phasing
from src.postfilter import PostFilter
from src.filtering import has_good_quality, cut_low_quality

from src.report import (
    ChromEnum, chrom_from_string,
    write_all, write_alignment, write_histogram_nomenclature, write_report
)

# define base mapping to regex for nucleotide symbols
base_mapping = {
    'A': 'A',     'C': 'C',     'G': 'G', 'T': 'T',
    'R': '[GA]',  'Y': '[CT]',  'K': '[GT]', 'M': '[AC]', 'S': '[GC]', 'W': '[AT]',
    'D': '[GAT]', 'H': '[ACT]', 'V': '[GCA]',  # AGT missing?
    'N': '[ACTG]'
}


DANTE_DESCRIPTION = '''
    DANTE = Da Amazing NucleoTide Exposer (Remastered)
    --------------------------------------------------
Genotyping and reporting from annotated reads generated by the remaSTR
program. The reads are filtered, clustered, and a genotype is inferred for
each motif. If a verbose option is switched on, DANTE creates a directory
for each of the annotated motifs and a summary report in HTML (report.html).
Otherwise only a table with all genotypes, confidences, and supporting
information.
'''


def load_arguments() -> argparse.Namespace:
    """
    Loads and parses the arguments.
    :return: args - parsed arguments
    """
    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description=textwrap.dedent(DANTE_DESCRIPTION)
    )

    postfilter = parser.add_argument_group('Post-filter')
    postfilter.add_argument(
        '--min-flank-len', '-fl', type=positive_int, default=3,
        help='Minimal flank length in bases. Default=3'
    )
    postfilter.add_argument(
        '--min-rep-len', '-rl', type=positive_int, default=3,
        help='Minimal repetition length in bases. Default=3'
    )
    postfilter.add_argument(
        '--min-rep-cnt', '-rc', type=positive_int, default=1,
        help='Minimal repetition count. Default=1'
    )
    postfilter.add_argument(
        '--max-abs-error', '-ea', type=positive_int, default=None,
        help='Maximal number of errors. Default=All'
    )
    postfilter.add_argument(
        '--max-rel-error', '-er', type=probability, default=1.0,
        help='Maximal ratio of errors to read length. Default=All'
    )

    options = parser.add_argument_group('Options')
    options.add_argument(
        '--start-motif', type=positive_int, default=0,
        help='Starting motif index (from 0). Default=0'
    )
    options.add_argument(
        '--max-motifs', type=positive_nonzero_int, default=None,
        help='Maximal number of motifs to load. Default: All'
    )
    options.add_argument(
        '--nomenclatures', '-n', type=positive_int, default=5,
        help='Number of nomenclature strings to add to reports. Default=5'
    )
    options.add_argument(
        '--output-dir', '-o', type=str, default="dante_out",
        help='Output destination (directory). Default=./dante_out/'
    )
    options.add_argument(
        '--deduplicate', '-d', action='store_true',
        help='Turn on the deduplication of reads.'
    )
    options.add_argument(
        '--verbose', '-v', action='store_true',
        help='Print all the outputs. Default is to print only the result table to stdout.'
    )
    options.add_argument(
        '--processes', '-p', type=positive_nonzero_int, default=8,
        help='Processes to use. Default=8'
    )
    options.add_argument(
        '--cutoff-alignments', type=positive_int, default=20,
        help='How many bases to keep beyond annotated part. Provide negative for no cutoff. Default=20'
    )
    options.add_argument(
        '--male', action='store_true',
        help='Indicate that the sample is male. Process motifs from chrX/chrY as mono-allelic.'
    )

    debug = parser.add_argument_group('Debug')
    debug.add_argument(
        '--skip-quality-under', type=positive_int, default=0,
        help='Skip reads that have quality lower than this value. Default=0, so skip none.'
    )
    debug.add_argument(
        '--cut-quality-under', type=positive_int, default=0,
        help='Cut parts of reads that have quality lower than this value. Default=0, so cut nothing.'
    )

    args = parser.parse_args()

    if args.output_dir is None:
        args.output_dir = os.getcwd()
    if args.cutoff_alignments < 0:
        args.cutoff_alignments = None

    return args


def change_suffix(filename: str, suffix: str) -> str:
    """
    Change suffix into a new one.
    :param filename: str - filename
    :param suffix: str - string to append
    :return: str - new filename with new suffix
    """
    return filename[:filename.rfind('.')] + suffix


# TODO: cutoff-alignments's help and this function are misleading. Resolve!
def positive_int(value: str, max_limit: int = None) -> int:
    """
    Represents positive decimal number, 0 included
    :param value: string value to estimate
    :param max_limit: maximal allowed value, skip validation if None
    :return: integer value, if can be converted into positive int else ArgumentTypeError
    """
    try:
        int_value = int(value)
    except ValueError:
        raise argparse.ArgumentTypeError(f'Value {value} is not integer')
    if int_value < 0:
        raise argparse.ArgumentTypeError(f'Value {value} is negative')
    if max_limit is not None and max_limit < int_value:
        raise argparse.ArgumentTypeError(f'Value {value} must be lower or equal to {max_limit}')
    return int_value


def positive_nonzero_int(value: str) -> int:
    """
    Represents positive decimal number, 0 excluded
    :param value: string value to estimate
    :return: integer value, if can be converted into positive int else ArgumentTypeError
    """
    int_value = positive_int(value)
    if int_value == 0:
        raise argparse.ArgumentTypeError(f'Value {value} cannot be 0')
    return int_value


def probability(value: str) -> float:
    """
    Validator for float value in interval <0, 1>
    :param value: String value to validate
    :return: float value or ArgumentTypeError
    """
    try:
        float_value = float(value)
    except ValueError:
        raise argparse.ArgumentTypeError(f'Value {value} is not float')
    if 0 <= float_value <= 1:
        return float_value
    else:
        raise argparse.ArgumentTypeError(f'Value {value} is not in interval <0, 1>')


def nonempty_file(file_path: str) -> str:
    """
    Checks if the filename in input is non-empty file.
    :param file_path: str - filename to check
    :return: str - filename
    """
    if not os.path.exists(file_path):
        raise argparse.ArgumentTypeError(f'File {file_path} does not exist')
    if os.path.getsize(file_path) == 0:
        raise argparse.ArgumentTypeError(f'File {file_path} is empty')
    return file_path


class Motif:
    """
    Class to represent DNA motifs.

    :ivar chrom: Chromosome name.
    :ivar start: Start position of the motif.
    :ivar end: End position of the motif.
    :ivar modules: A list of tuples containing sequence and repetition count.
    :ivar name: name of the Motif
    :ivar motif: motif nomenclature
    """

    def __init__(self, motif: str, name: str | None = None):
        """
        Initialize a Motif object.
        :param motif: The motif string in the format "chrom:start_end[A][B]..."
        :param name: optional name of the motif
        """
        # remove whitespace
        self.motif = motif.strip().replace(' ', '')
        self.name = (name if name is not None else self.motif).replace(':', '-').replace('.', '_').replace('/', '_')

        # extract prefix, first number, second number
        self.chrom, start, end, remainder = re.match(r'([^:]+):g\.(\d+)_(\d+)(.*)', self.motif).groups()

        # extract sequence and repetition count
        self.modules = [(str(seq), int(num)) for seq, num in re.findall(r'([A-Z]+)\[(\d+)', remainder)]
        self.modules = [('left_flank', 1)] + self.modules + [('right_flank', 1)]

        # convert to ints
        self.start = int(start)
        self.end = int(end)

    def __getitem__(self, index: int) -> Tuple[str, int]:
        """
        Returns module at given index.
        :param index: The index of the module to fetch.
        :return: The module at the given index.
        """
        return self.modules[index]

    def __str__(self) -> str:
        """
        Returns string representation of the Motif object.
        :return: String representation in the format "chrom:start_end[A][B]..."
        """
        return f'{self.chrom}:g.{self.start}_{self.end}' + self.modules_str(include_flanks=False)

    def __lt__(self, obj):
        """
        Less than for sorting purposes.
        :return: bool - if this object comes before the other
        """
        return self.name < obj.name

    def __eq__(self, obj):
        """
        Equal to for sorting purposes.
        :return: bool - if this object is equal to the other
        """
        return self.name == obj.name

    def modules_str(self, include_flanks: bool = False) -> str:
        """
        Returns string representation of modules
        :param include_flanks: bool - include flank modules?
        :return: String representation of modules
        """
        if include_flanks:
            return ''.join([f'{seq}[{num}]' for seq, num in self.modules])
        return ''.join([f'{seq}[{num}]' for seq, num in self.modules[1:-1]])

    def module_str(self, module_number: int) -> str:
        """
        Returns string representation of modules
        :param module_number: int - module number
        :return: String representation of modules
        """
        seq, num = self.modules[module_number]
        return f'{seq}[{num}]'

    def dir_name(self) -> str:
        """
        Returns possible directory name of the motif.
        :return: str - directory name for the motif
        """
        return self.name

    def get_modules(self) -> List[Tuple[str, int]]:
        """
        Returns list of modules.
        :return: List of tuples containing sequence and repetition count.
        """
        return self.modules

    def get_repeating_modules(self) -> List[Tuple[int, str, int]]:
        """
        Returns list of modules with more than one repetition.
        :return: List of tuples containing index, sequence, and repetition count.
        """
        return [(int(i), str(seq), int(num)) for i, (seq, num) in enumerate(self.modules) if num > 1]

    def get_location_subpart(self, index: int) -> Tuple[int, int]:
        """
        Returns the chromosome location of a subpart of a motive
        :param index: int - index of a module
        :return: start and end location of the subpart
        """
        start = self.start
        for module in self.modules[1: index]:
            seq, rep = module
            start += len(seq) * rep

        return start, start + len(self.modules[index][0]) * self.modules[index][1]


class Annotation:
    """
    Encapsulate sequence of states from HMM and provide its readable representation and filters
    """

    def __init__(
        self, read_id: str, mate_order: int, read_seq: str, expected_seq: str,
        states: str, probability: float, motif: Motif
    ):
        """
        :param read_id: str - read ID
        :param read_seq: str - read sequence
        :param mate_order: int - mate order (0 - unpaired, 1 - left pair, 2 - right pair)
        :param expected_seq: str - expected sequence as in motif
        :param states: str - sequence of states (numbers of modules)
        :param probability: Probability of generating sequence by the most likely sequence of HMM states
        :param motif: Sequence of tuples (sequence, repeats) as specified by user
        """

        # Store arguments into instance variables
        self.read_id = read_id
        self.mate_order = mate_order
        self.ordered = mate_order > 0
        self.left_pair = mate_order == 1
        self.read_seq = read_seq
        self.expected_seq = expected_seq
        self.states = states
        self.probability = probability
        self.motif = motif
        self.n_modules = len(motif.get_modules())

        # Calculate insertion/deletion/mismatch string
        self.mismatches_string = self.__get_errors()

        # Calculate number of insertions, deletions and normal bases
        self.n_insertions = self.mismatches_string.count('I')
        self.n_deletions = self.mismatches_string.count('D')
        self.n_mismatches = self.mismatches_string.count('M')

        # Number of STR motif repetitions and sequences of modules
        self.module_bases = self.__get_bases_per_module()
        self.module_repetitions = self.__get_module_repetitions()
        self.module_sequences = self.__get_module_sequences()

        # get left flank length
        self.left_flank_len = self.__get_left_flank()

    def __str__(self) -> str:
        """
        Return the annotation.
        :return: str - annotation
        """
        return '\n'.join([f'{self.read_id} {str(self.module_bases)} {str(self.module_repetitions)}', self.read_seq,
                          self.expected_seq, self.states, self.mismatches_string])

    def __get_errors(self) -> str:
        """
        Count errors in annotation and the error line.
        :return: str - error line
        """
        err_line = []
        for exp, read in zip(self.expected_seq.upper(), self.read_seq.upper()):
            if exp == '-' or read in base_mapping.get(exp, ''):
                err_line.append('_')
            elif read == '_':
                err_line.append('D')
            elif exp == '_':
                err_line.append('I')
            else:
                err_line.append('M')

        return ''.join(err_line)

    def __get_bases_per_module(self) -> tuple[int, ...]:
        """
        List of integers, each value corresponds to number of bases of input sequence that were generated by the module
        :return: Number of bases generated by each module
        """
        # Count the module states
        return tuple(self.states.count(chr(ord('0') + i)) for i in range(self.n_modules))

    def __get_left_flank(self) -> int:
        """
        Get length of a left flank.
        :return: int - number of bases of left flank before module '0' (usually module '0' is still left flank)
        """
        for i, state in enumerate(self.states):
            if state != '-':
                return i
        return len(self.states)

    def __get_module_repetitions(self) -> tuple[int, ...]:
        """
        List of integers, each value corresponds to number of repetitions of module in annotation
        :return: Number of repetitions generated by each module
        """
        # Count the module states
        repetitions = self.__get_bases_per_module()

        # Divide by the module length where applicable
        # TODO this is not right for grey ones, where only closed ones should be counted, so round is not right.
        return tuple([1 if reps == 1 and cnt > 0 else round(cnt / len(seq))
                      for (seq, reps), cnt in zip(self.motif.get_modules(), repetitions)])

    def __get_module_sequences(self) -> tuple[str, ...]:
        """
        List of sequences, each per module
        :return: list(str)
        """
        sequences = [''] * self.n_modules
        for i in range(self.n_modules):
            state_char = chr(ord('0') + i)
            first = self.states.find(state_char)
            if first > -1:
                last = self.states.rfind(state_char)
                sequences[i] = self.read_seq[first:last + 1]
        return tuple(sequences)

    def get_module_errors(self, module_num: int, overhang: int = None) -> tuple[int, int, int]:
        """
        Get the number of insertions and deletions or mismatches in a certain module.
        If overhang is specified, look at specified number of bases around the module as well.
        :param module_num: int - 0-based module number to count errors
        :param overhang: int - how long to look beyond module, if None, one length of STR module
        :return: int, int, int - number of insertions and deletions, mismatches, length of the interval
        """
        # get overhang as module length
        if overhang is None:
            seq, _ = self.motif.get_modules()[module_num]
            overhang = len(seq)

        # define module character
        char_to_search = chr(ord('0') + module_num)

        # if the annotation does not have this module, return 0
        if char_to_search not in self.states:
            return 0, 0, 0

        # search for the annotation of the module
        start = max(0, self.states.find(char_to_search) - overhang)
        end = min(self.states.rfind(char_to_search) + overhang + 1, len(self.states))

        # count errors
        indels = self.mismatches_string[start:end].count('I') + self.mismatches_string[start:end].count('D')
        mismatches = self.mismatches_string[start:end].count('M')

        # return indels, mismatches, and length
        return indels, mismatches, end - start

    def info_value(self) -> (int, int):
        """
        Evaluate the info value of the Annotation.
        :return: int, int
        """
        return sum(self.module_repetitions), sum(self.module_bases)

    def info_value_str(self, index_str: int) -> (int, int, int):
        """
        Evaluate the info value of the Annotation at the STR location
        :param index_str: int - index of the STR
        :return: int, int, int
        """
        return self.primers(index_str), self.module_repetitions[index_str], self.module_bases[index_str]

    def has_required_modules(self, required_repetitions: list[int]) -> bool:
        """
        Validate, if read is annotated with sufficient number of modules
        :param required_repetitions: list of number of required repetitions, one for each module
        :return: True, if annotation has required number of repetition for each module
        """
        if not required_repetitions:
            return True

        for repetition, required_repetition in zip(self.module_repetitions, required_repetitions):
            if repetition < required_repetition:
                return False
        return True

    def has_required_bases(self, required_bases: list[int]) -> bool:
        """
        Validate, if read bases are sufficiently annotated
        :param required_bases: list of number of required annotated bases, one for each module
        :return: True, if annotation has required number of annotated bases for each module
        """
        if not required_bases:
            return True

        for bases, required_base in zip(self.module_bases, required_bases):
            if bases < required_base:
                return False
        return True

    def has_one_primer(
        self, required_bases: list[int], required_repetitions: list[int], index_rep: int, index_rep2: int = None
    ) -> bool:
        """
        Validate, if at least one primer is sufficiently annotated, in case of 2 repetitions, we check only the
        :param required_bases: list of number of required annotated bases, one for each module
        :param required_repetitions: list of number of required annotated modules
        :param index_rep: int - index of the repetition, that we are looking at
        :param index_rep2: int - index of the second repetition, that we are looking at
        :return: True, if annotation has at least one primer is sufficiently annotated
        """
        # if it is not interesting just throw it away
        if not self.is_annotated_right():
            return False

        # if no filter, accept all
        if required_bases is None and required_repetitions is None:
            return True

        def check_reqs(index: int) -> bool:
            """
            Check if requirements are met on 'index'
            :param index: int - index of a module
            :return: bool - requirements are met?
            """
            if required_bases is not None and self.module_bases[index] < required_bases[index]:
                return False
            if required_repetitions is not None and self.module_repetitions[index] < required_repetitions[index]:
                return False
            return True

        if index_rep2 is None:
            index_rep2 = index_rep
        index_rep, index_rep2 = min(index_rep, index_rep2), max(index_rep, index_rep2)

        # if the module has right primer, and it is clipped on the left
        if index_rep2 + 1 < len(required_bases) and self.states[0] != '-' \
                and check_reqs(index_rep2 + 1) and check_reqs(index_rep):
            return True
        # if the module has left primer, and it is clipped on the right
        if index_rep - 1 >= 0 and self.states[-1] != '-' and check_reqs(index_rep - 1) and check_reqs(index_rep2):
            return True
        return False

    def has_less_errors(self, max_errors: float | int, relative=False) -> bool:
        """
        Check if this annotation has fewer errors than max_errors.
        Make it relative to the annotated length if relative is set.
        :param max_errors: int/float - number of max_errors (relative if relative is set)
        :param relative: bool - if the errors are relative to the annotated length
        :return: bool - True if the number of errors is less than allowed
        """
        errors = self.n_deletions + self.n_insertions + self.n_mismatches

        if max_errors is None or errors == 0:
            return True

        if relative:
            return errors / float(sum(self.module_bases)) <= max_errors
        else:
            return errors <= max_errors

    def primers(self, index_rep: int) -> int:
        """
        Count how any primers it has on repetition index.
        :param index_rep: int - index of the repetition, that we are looking at
        :return: int - number of primers (0-2)
        """
        primers = 0
        if index_rep > 0 and self.module_repetitions[index_rep - 1] > 0:
            primers += 1
        if index_rep + 1 < len(self.module_repetitions) and self.module_repetitions[index_rep + 1] > 0:
            primers += 1
        return primers

    def is_annotated_right(self) -> bool:
        """
        Is it annotated in a way that it is interesting?
        More than one module annotated + modules are not missing in the middle.
        :return: bool - annotated right?
        """

        # remove those that starts/ends in background but don't have a neighbour module
        starts_background = self.states[0] in '_-'
        ends_background = self.states[-1] in '_-'
        if starts_background and self.module_repetitions[0] == 0:
            return False
        if ends_background and self.module_repetitions[-1] == 0:
            return False

        # remove those with jumping modules
        started = False
        ended = False
        for repetition in self.module_repetitions:
            if repetition > 0:
                started = True
                if ended:
                    return False
            if repetition == 0 and started:
                ended = True

        # pass?
        return True

    def same_start_fragment(self, annotation: Annotation) -> bool:
        """
        Return True if both sequences can be produced from the same start of a fragment.
        :param annotation: Annotation - second annotation
        :return: bool - True if both sequences can be produced from the same start of a fragment
        """
        comp_length = min(len(self.read_seq), len(annotation.read_seq))
        return self.read_seq[:comp_length] == annotation.read_seq[:comp_length]

    def same_end_fragment(self, annotation: Annotation) -> bool:
        """
        Return True if both sequences can be produced from the same end of a fragment.
        :param annotation: Annotation | None - second annotation
        :return: bool - True if both sequences can be produced from the same end of a fragment
        """
        comp_length = min(len(self.read_seq), len(annotation.read_seq))
        return self.read_seq[-comp_length:] == annotation.read_seq[-comp_length:]

    def get_str_repetitions(self, index_str: int) -> Optional[tuple[bool, int]]:
        """
        Get the number of str repetitions for a particular index.
        :param index_str: int - index of a str
        :return: (bool, int) - closed?, number of str repetitions
        """
        if self.is_annotated_right():
            primer1 = index_str > 0 and self.module_repetitions[index_str - 1] > 0
            primer2 = index_str + 1 < len(self.module_repetitions) and self.module_repetitions[index_str + 1] > 0
            if primer1 or primer2:
                return primer1 and primer2, self.module_repetitions[index_str]
        return None

    @staticmethod
    def find_with_regex(read_sequence: str, motif_sequence: str, search_pos: int = 0) -> int:
        """
        Find the first occurrence of a motif sequence in the read sequence using regular expressions.
        :param read_sequence: The sequence to search in.
        :param motif_sequence: The motif sequence (as a regex) to search for.
        :param search_pos: The position to start the search from.
        :return: int - The start position of the first occurrence of the motif sequence. Returns -1 if not found.
        """
        # convert motif sequence to regex
        motif_regex = ''.join(base_mapping[char] for char in motif_sequence)

        # compile the regular expression pattern
        pattern = re.compile(motif_regex)

        # search for the pattern in the read sequence starting from search_pos
        match = pattern.search(read_sequence, search_pos)

        # return the start position if a match is found, else return -1
        return match.start() if match else -1

    def get_nomenclature(
        self, index_rep: int = None, index_rep2: int = None, include_flanking: bool = True
    ) -> str:
        """
        Get HGVS nomenclature.
        :param index_rep: int - index of the first repetition (None if include all)
        :param index_rep2: int - index of the second repetition (None if include all)
        :param include_flanking: boolean - include flanking regions (i.e. first and last module)
        :return: str - HGVS nomenclature string
        """
        # prepare data
        if index_rep is not None:
            if index_rep2 is not None:
                data = zip(
                    [self.module_repetitions[index_rep], self.module_repetitions[index_rep2]],
                    [self.motif[index_rep], self.motif[index_rep2]],
                    [self.module_sequences[index_rep], self.module_sequences[index_rep2]]
                )
            else:
                data = zip(
                    [self.module_repetitions[index_rep]],
                    [self.motif[index_rep]],
                    [self.module_sequences[index_rep]]
                )
        elif include_flanking:
            data = zip(self.module_repetitions, self.motif.get_modules(), self.module_sequences)
        else:
            data = zip(self.module_repetitions[1:-1], self.motif[1:-1], self.module_sequences[1:-1])

        # iterate and build the nomenclature string
        nomenclatures = []
        for repetitions, (motif_sequence, _), read_sequence in data:
            nomenclature = ''
            if repetitions == 1:
                if len(read_sequence) > 0:
                    nomenclature += f'{read_sequence}[1]'
            else:
                reps = 0
                search_pos = 0
                found_rep_seq = ''
                while True:
                    search_found = self.find_with_regex(read_sequence, motif_sequence, search_pos)
                    if search_found == search_pos:
                        # setup current rep. sequence
                        if reps == 0:
                            found_rep_seq = read_sequence[search_found:search_found + len(motif_sequence)]

                        if read_sequence[search_found:search_found + len(motif_sequence)] == found_rep_seq:
                            # regular continuation
                            reps += 1
                        else:
                            # interruption, but in line with searched motif
                            nomenclature += f'{found_rep_seq}[{reps}]'
                            found_rep_seq = read_sequence[search_found:search_found + len(motif_sequence)]
                            reps = 1
                    elif search_found == -1:
                        # the end, we did not find any other STRs
                        if reps > 0:
                            nomenclature += f'{found_rep_seq}[{reps}]'
                        if len(read_sequence[search_pos:]) > 0:
                            nomenclature += f'{read_sequence[search_pos:]}[1]'
                        break
                    else:
                        # some interruption
                        if reps > 0:
                            nomenclature += f'{found_rep_seq}[{reps}]'
                        if len(read_sequence[search_pos:search_found]) > 0:
                            nomenclature += f'{read_sequence[search_pos:search_found]}[1]'
                        found_rep_seq = read_sequence[search_found:search_found + len(motif_sequence)]
                        reps = 1
                    # update search pos and iterate
                    search_pos = search_found + len(motif_sequence)
            nomenclatures.append(nomenclature)

        return '\t'.join(nomenclatures)

    def get_shortened_annotation(self, shorten_length: int) -> Annotation:
        """
        Get shortened annotation with specified shorten length beyond annotated modules.
        :param shorten_length: int - how many bases to keep beyond modules
        :return: Annotation - shortened annotation
        """

        # search for start
        start = -1
        for i in range(len(self.states)):
            if self.states[i] != '-':
                start = i
                break

        # search for end
        end = -1
        for i in range(len(self.states) - 1, -1, -1):
            if self.states[i] != '-':
                end = i
                break

        # adjust start and end for shorten length
        start = max(start - shorten_length, 0)
        end = min(end + 1 + shorten_length, len(self.states))  # +1 for use as list range

        # return shortened Annotation
        return Annotation(self.read_id, self.mate_order, self.read_seq[start:end], self.expected_seq[start:end],
                          self.states[start:end], self.probability, self.motif)


class AnnotationPair:
    """
    Encapsulate annotation pairs.
    """

    def __init__(self, ann1: Annotation, ann2: Annotation | None):
        """
        Initialize the AnnotationPair object
        :param ann1: Annotation - first annotation of a pair
        :type ann1: Annotation
        :param ann2: Annotation - second annotation of a pair
        :type ann2: Annotation | None
        """
        assert ann1 is not None
        self.ann1 = ann1
        self.ann2 = ann2

    def __eq__(self, second_pair: AnnotationPair) -> bool:
        """
        Annotation pairs equal when they are produced by the same fragment.
        :param second_pair: AnnotationPair - second annotation pair
        :type second_pair: AnnotationPair
        :return: bool - whether the annotation pairs are produced by the same fragment
        """
        # first check if we deal with simple annotations
        if self.ann1 is None:
            return second_pair.ann2 is not None and self.ann2.same_end_fragment(second_pair.ann2)

        if self.ann2 is None:
            return second_pair.ann1 is not None and self.ann1.same_start_fragment(second_pair.ann1)

        # return the full comparison
        return ((second_pair.ann1 is None or self.ann1.same_start_fragment(second_pair.ann1))
                and (second_pair.ann2 is None or self.ann2.same_end_fragment(second_pair.ann2)))

    def __str__(self):
        return '\n'.join(['1', str(self.ann1), '2', str(self.ann2)])

    def has_required_modules(self, required_repetitions: list[int]) -> bool:
        """
        Validate, if read modules are sufficiently annotated (in at least one of the reads)
        :param required_repetitions: list of number of required annotated modules
        :return: True, if one of the annotations has required number of annotated modules
        """
        left = self.ann1 is not None and self.ann1.has_required_modules(required_repetitions)
        right = self.ann2 is not None and self.ann2.has_required_modules(required_repetitions)
        return left or right

    def has_required_bases(self, required_bases: list[int]) -> bool:
        """
        Validate, if read bases are sufficiently annotated (in at least one of the reads)
        :param required_bases: list of number of required annotated bases, one for each module
        :return: True, if one of the annotations has required number of annotated bases for each module
        """
        left = self.ann1 is not None and self.ann1.has_required_bases(required_bases)
        right = self.ann2 is not None and self.ann2.has_required_bases(required_bases)
        return left or right

    def has_one_primer(
        self, required_bases: list[int], required_repetitions: list[int], index_rep: int, index_rep2: int = None
    ) -> bool:
        """
        Validate, if at least one primer is sufficiently annotated (in at least one of the reads)
        :param required_bases: list of number of required annotated bases, one for each module
        :param required_repetitions: list of number of required annotated modules
        :param index_rep: int - index of the repetition, that we are looking at
        :param index_rep2: int - index of the second repetition, that we are looking at
        :return: True, if one of the annotations has at least one primer is sufficiently annotated
        """
        left = self.ann1 is not None and self.ann1.has_one_primer(required_bases, required_repetitions, index_rep, index_rep2)
        rght = self.ann2 is not None and self.ann2.has_one_primer(required_bases, required_repetitions, index_rep, index_rep2)
        return left or rght

    def more_info_than(self, second_pair: AnnotationPair) -> bool:
        """
        Check if this AnnotationPair has more info than second AnnotationPair
        :param second_pair: AnnotationPair - second annotation pair
        :return: bool - True if it has more info than the other AnnotationPair
        """

        # first compare if both has annotations:
        if self.ann2 is None:
            return False

        if second_pair.ann2 is None:
            return True

        # then return those that have more annotated modules, or bases:
        m1f, b1f = self.ann1.info_value()
        m2f, b2f = self.ann2.info_value()

        m1s, b1s = second_pair.ann1.info_value()
        m2s, b2s = second_pair.ann2.info_value()

        return (m1f + m2f, b1f + b2f) > (m1s + m2s, b1s + b2s)

    def get_more_informative_annotation(self, index_str: int = None) -> Annotation:
        """
        Return the more informative Annotation from the two.
        :return: Annotation - the more informative annotation
        """
        # If the second is non-existent, return the first
        if self.ann2 is None:
            return self.ann1

        # It the STR index is not provided return the "absolutely" more informative,
        # else return the more informative on that STR
        if index_str is None:
            if self.ann1.info_value() >= self.ann2.info_value():
                return self.ann1
            else:
                return self.ann2
        else:
            if self.ann1.info_value_str(index_str) >= self.ann2.info_value_str(index_str):
                return self.ann1
            else:
                return self.ann2

    def get_str_repetitions(self, index_str: int) -> (bool, int):
        """
        Get the number of str repetitions for a particular index.
        :param index_str: int - index of a str
        :return: (bool, int) - closed?, number of str repetitions
        """

        def add_primers(annotation: Annotation, module_num: int) -> list[(bool, int)]:
            """
            Add str repetitions from one annotation into an array of results.
            :param annotation: Annotation - input annotation
            :param module_num: int - index of a str
            :return: list(bool, int) - closed?, number of str repetitions
            """
            primer1 = module_num > 0 and annotation.module_repetitions[module_num - 1] > 0
            primer2 = module_num + 1 < len(annotation.module_repetitions) and annotation.module_repetitions[module_num + 1] > 0
            if primer1 or primer2:
                return [(primer1 and primer2, annotation.module_repetitions[module_num])]
            return []

        results = []
        if self.ann1 is not None and self.ann1.is_annotated_right():
            results.extend(add_primers(self.ann1, index_str))
        if self.ann2 is not None and self.ann2.is_annotated_right():
            results.extend(add_primers(self.ann2, index_str))

        # return the highest (first see if it is closed and then pick the highest number):
        if len(results) > 0:
            return sorted(results)[-1]
        return None


def annotations_to_pairs(annots: list[Annotation]) -> list[AnnotationPair]:
    """
    Convert an array of annotations to annotation pairs array.
    :param annots: list(Annotation) - annotations
    :return: list(AnnotationPair)
    """

    # sort:
    sorted_list = sorted(annots, key=lambda annot: (annot.read_id, annot.left_pair))

    # remove duplicates:
    seen = set()
    deduplicated = []
    for ann in sorted_list:
        if (ann.read_id, ann.left_pair) not in seen:
            seen.add((ann.read_id, ann.left_pair))
            deduplicated.append(ann)

    result = []

    i = 0
    while i < len(deduplicated):
        if i + 1 < len(deduplicated) and deduplicated[i].read_id == deduplicated[i + 1].read_id:
            assert deduplicated[i].ordered and deduplicated[i + 1].ordered and deduplicated[i].left_pair != deduplicated[i + 1].left_pair
            result.append(AnnotationPair(deduplicated[i], deduplicated[i + 1]))
            i += 2
        else:
            result.append(AnnotationPair(deduplicated[i], None))
            i += 1

    return result


def pairs_to_annotations(annotation_pairs: list[AnnotationPair]) -> list[Annotation]:
    """
    Convert an array of annotations pairs to annotation array.
    :param annotation_pairs: list(AnnotationPair) - annotations
    :return: list(Annotation)
    """
    annots = []
    for ap in annotation_pairs:
        if ap.ann1 is not None:
            annots.append(ap.ann1)
        if ap.ann2 is not None:
            annots.append(ap.ann2)

    return annots


def pairs_to_annotations_pick(annotation_pairs: list[AnnotationPair], index_str: int | None) -> list[Annotation]:
    """
    Convert an array of annotations pairs to annotation array. Leave only the more informative one.
    :param annotation_pairs: list(AnnotationPair) - annotations
    :param index_str: int: index of the STR to look at or None if we should get the whole motif into account
    :return: list(Annotation)
    """
    return [ap.get_more_informative_annotation(index_str) for ap in annotation_pairs]


# TODO make this faster/parallelize -
# takes too long when number of found reads is more than 10.000-100.000 (1min at 7.500, 4h at 400.000)
def remove_pcr_duplicates(annot_pairs: list[AnnotationPair]) -> (list[AnnotationPair], list[AnnotationPair]):
    """
    Remove PCR duplicates -- deduplicate the annotation pair list.
    :param annot_pairs: list(AnnotationPair) - list of Annotation Pairs
    :return: list(AnnotationPair), list(AnnotationPair) - deduplicated list and duplications
    """
    def remove_none(ann_pairs: list[AnnotationPair], first: bool = True) -> list[AnnotationPair]:
        """
        Remove annotation pairs with None first (second) annotation from the pair.
        :param ann_pairs: list(AnnotationPair) - list of Annotation Pairs
        :param first: bool - look at the first annotation from the pair?
        :return: list(AnnotationPair) - list of Annotation Pairs without None pairs
        """
        return [ap for ap in ann_pairs if (first and ap.ann1 is not None) or (not first and ap.ann2 is not None)]

    def restore_none(pairs_with_none: list[AnnotationPair], first: bool = True) -> list[AnnotationPair]:
        """
        Restore annotation pairs with None first (second) annotation from the pair.
        :param pairs_with_none: list(AnnotationPair) - list of Annotation Pairs with None annotations
        :param first: bool - look at the first annotation from the pair?
        :return: list(AnnotationPair) - list of Annotation Pairs with restored Annotation Pairs with None annotation
        """
        return [ap for ap in pairs_with_none if (first and ap.ann1 is None) or (not first and ap.ann2 is None)]

    def deduplicate(ann_pairs: list[AnnotationPair]) -> (list[AnnotationPair], list[AnnotationPair]):
        """
        Remove PCR duplicates -- deduplicate the annotation pair list.
        :param ann_pairs: list(AnnotationPair) - list of Annotation Pairs sorted by annotation_1 or annotation_2
        :return: list(AnnotationPair), list(AnnotationPair) - deduplicated list and duplications
        """
        dedup = []
        duplic = []

        if not ann_pairs:
            return [], []

        # Find duplicates by comparing neighbours in sorted list
        prev_ap = ann_pairs[0]
        for curr_ap in ann_pairs[1:]:
            if prev_ap == curr_ap:
                if prev_ap.more_info_than(curr_ap):
                    duplic.append(curr_ap)
                else:
                    duplic.append(prev_ap)
                    prev_ap = curr_ap
            else:
                dedup.append(prev_ap)
                prev_ap = curr_ap

        dedup.append(prev_ap)

        return dedup, duplic

    if not annot_pairs:
        return [], []

    # Deduplication according to first annotation in pair
    curr_pairs = remove_none(annot_pairs, True)
    curr_pairs = sorted(curr_pairs, key=lambda ap: ap.ann1.read_seq)
    deduplicated_1, duplicates_1 = deduplicate(curr_pairs)

    curr_pairs = deduplicated_1 + restore_none(annot_pairs, True)

    # Deduplication according to second annotation in pair
    curr_pairs = remove_none(curr_pairs, False)
    curr_pairs = sorted(curr_pairs, key=lambda ann: ann.ann2.read_seq[::-1])
    deduplicated_2, duplicates_2 = deduplicate(curr_pairs)

    deduplicated = deduplicated_2 + restore_none(deduplicated_1, False)
    duplicates = duplicates_1 + duplicates_2

    return deduplicated, duplicates


def shorten_str(string: str, max_length: int = 40, ellipsis_str: str = '...') -> str:
    """
    Shorten string to max_length and include ellipsis.
    :param string: str - string to shorten
    :param max_length: int - maximum length to shorten to
    :param ellipsis_str: str - ellipsis to add to end of string
    :return: str - shortened string
    """
    if len(string) > max_length:
        return string[:max_length - len(ellipsis_str)] + ellipsis_str
    else:
        return string


def errors_per_read(
    errors: list[tuple[int, int, int]], relative: bool = False
) -> tuple[float | str, float | str]:
    """
    Count number of errors per read. Relative per length or absolute number.
    :param errors: list[tuple[int, int, int]] - indels, mismatches and length of module
    :param relative: bool - relative?
    :return: tuple[float, float] - number of indels, mismatches per hundred reads
    """
    # if we have no reads, return '---'
    if len(errors) == 0:
        return '---', '---'

    if relative:
        mean_length = np.mean([length for _, _, length in errors])
        return (
            float(np.mean([indels / float(length) for indels, _, length in errors]) * mean_length),
            float(np.mean([mismatches / float(length) for _, mismatches, length in errors]) * mean_length)
        )
    else:
        return (
            float(np.mean([indels for indels, _, _ in errors])),
            float(np.mean([mismatches for _, mismatches, _ in errors]))
        )


def generate_result_line(
    motif_class: Motif, predicted: tuple[str | int, str | int], confidence: tuple[float | str, ...],
    qual_num: int, primer_num: int, filt_num: int, module_number: int,
    qual_annot: list[Annotation] | None = None,
    second_module_number: int | None = None
) -> dict:
    """
    Generate result line from the template string.
    :param motif_class: Motif - motif class
    :param predicted: tuple[str, str] - predicted alleles (number or 'B'/'E')
    :param confidence: tuple[7x float/str] - confidences of prediction
    :param qual_num: int - number of reads with both primers
    :param primer_num: int - number of reads with exactly one primer
    :param filt_num: int - number of filtered out reads (no primers, many errors, ...)
    :param module_number: int - module number in motif
    :param qual_annot: list[Annotation] - list of quality annotations for error and number of reads
    :param second_module_number: int/None - second module number in motif
    :return: dict - result dictionary
    """
    # setup motif info
    start, end = motif_class.get_location_subpart(module_number)
    motif_seq = motif_class.module_str(module_number)
    if second_module_number is not None:
        _, end = motif_class.get_location_subpart(second_module_number)
        motif_seq = ','.join(
            [motif_class.module_str(i) for i in range(module_number, second_module_number + 1)]
        )

    reads_a1: int | str
    reads_a2: int | str
    indels_rel: float | str
    indels_rel1: float | str
    indels_rel2: float | str
    mismatches_rel: float | str
    mismatches_rel1: float | str
    mismatches_rel2: float | str
    # get info about errors and number of reads from quality annotations if provided
    reads_a1 = reads_a2 = '---'
    indels_rel = mismatches_rel = '---'
    indels_rel1 = mismatches_rel1 = '---'
    indels_rel2 = mismatches_rel2 = '---'
    if qual_annot is not None:
        # get info about number of reads
        a1 = int(predicted[0]) if isinstance(predicted[0], int) else None
        a2 = int(predicted[1]) if isinstance(predicted[1], int) else None
        reads_a1 = 0 if a1 is None else len(
            [a for a in qual_annot if a.module_repetitions[module_number] == a1]
        )
        reads_a2 = 0 if a2 is None else len(
            [a for a in qual_annot if a.module_repetitions[module_number] == a2]
        )

        # get info about errors
        errors = [a.get_module_errors(module_number) for a in qual_annot]
        errors_a1 = [a.get_module_errors(module_number) for a in qual_annot
                     if a.module_repetitions[module_number] == a1]
        errors_a2 = [a.get_module_errors(module_number) for a in qual_annot
                     if a.module_repetitions[module_number] == a2]
        assert len([l for i, m, l in errors if l == 0]) == 0

        # extract error metrics
        indels_rel, mismatches_rel = errors_per_read(errors, relative=True)
        indels_rel1, mismatches_rel1 = errors_per_read(errors_a1, relative=True)
        indels_rel2, mismatches_rel2 = errors_per_read(errors_a2, relative=True)

    # return dictionary
    return {
        'motif_name': motif_class.name, 'motif_nomenclature': motif_class.motif, 'motif_sequence': motif_seq,
        'chromosome': motif_class.chrom, 'start': start, 'end': end, 'allele1': predicted[0],
        'allele2': predicted[1], 'confidence': confidence[0], 'conf_allele1': confidence[1],
        'conf_allele2': confidence[2], 'reads_a1': reads_a1, 'reads_a2': reads_a2, 'indels': indels_rel,
        'mismatches': mismatches_rel, 'indels_a1': indels_rel1, 'indels_a2': indels_rel2,
        'mismatches_a1': mismatches_rel1, 'mismatches_a2': mismatches_rel2, 'quality_reads': qual_num,
        'one_primer_reads': primer_num, 'filtered_reads': filt_num,
        'conf_background': confidence[3] if len(confidence) > 3 else '---',
        'conf_background_all': confidence[4] if len(confidence) > 4 else '---',
        'conf_extended': confidence[5] if len(confidence) > 5 else '---',
        'conf_extended_all': confidence[6] if len(confidence) > 6 else '---',
        'repetition_index': module_number
        if second_module_number is None
        else f'{module_number}_{second_module_number}'
    }


# this has mixed functionality - it does prediction and it does writing
def too_complex_function_inferring_and_creating_reports(
    args: argparse.Namespace,
    annotations1: list[Annotation],
    postfilter_class: PostFilter,
    motif_class: Motif,
    motif_dir: str,
    motif_str: str,
    module_number: int,
    read_distribution: npt.NDArray[np.int64],
    result_lines: list,
    prev_module: tuple[int, str, int] | None,
    file_pcolor: str | None,
    file_output: str | None
):
    monoallelic1 = args.male and chrom_from_string(motif_class.chrom) in [
        ChromEnum.X, ChromEnum.Y
    ]

    # setup post filtering - no primers, insufficient quality, ...
    qual_annot1, filt_annot1 = postfilter_class.get_filtered(annotations1, module_number, both_primers=True)
    primer_annot1, filt_annot2 = postfilter_class.get_filtered(filt_annot1, module_number, both_primers=False)

    # why is this a class?
    # run inference - this takes most of the time (for no --verbose)
    model = Inference(
        read_distribution, None, str_rep=args.min_rep_cnt,
        minl_primer1=args.min_flank_len, minl_primer2=args.min_flank_len,
        minl_str=args.min_rep_len
    )

    predicted1, confidence1 = model.genotype(
        qual_annot1, primer_annot1, module_number, file_pcolor, file_output,
        motif_str, monoallelic1
    )

    # append to the result line
    result_lines.append(generate_result_line(
        motif_class, predicted1, confidence1,
        len(qual_annot1), len(primer_annot1), len(filt_annot1),
        module_number, qual_annot=qual_annot1
    ))

    # infer phasing (if we are not on the first repeating module)
    last_num1 = None
    both_good_annot1 = None
    one_good_annot1 = None
    none_good_annot1 = None
    phasing1 = None
    supp_reads1 = None
    if prev_module is not None:
        # get the last module number
        last_num1 = prev_module[0]

        # post filtering
        both_good_annot1, filtered_annot1 = postfilter_class.get_filtered_list(
            annotations1, [last_num1, module_number], both_primers=[True, True]
        )
        left_good_annot1, left_bad_annot1 = postfilter_class.get_filtered_list(
            filtered_annot1, [last_num1, module_number], both_primers=[False, True]
        )
        right_good_annot1, none_good_annot1 = postfilter_class.get_filtered_list(
            left_bad_annot1, [last_num1, module_number], both_primers=[True, False]
        )
        one_good_annot1 = left_good_annot1 + right_good_annot1

        # infer phasing
        phasing1, supp_reads1 = phase(both_good_annot1, last_num1, module_number)

        # append to the result line
        result_lines.append(generate_result_line(
            motif_class, phasing1, supp_reads1,
            len(both_good_annot1), len(one_good_annot1), len(none_good_annot1),
            last_num1, second_module_number=module_number
        ))

    return (
        (qual_annot1, primer_annot1, filt_annot2),
        (both_good_annot1, one_good_annot1, none_good_annot1),
        phasing1, supp_reads1, confidence1, predicted1, result_lines, last_num1
    )


def report(
    args, motif_dir, motif_class, module_number, last_num1, prev_module,
    ann_qual, ann_primer, ann_filter, ann_2good, ann_1good, ann_0good,
    phasing, supp_reads, confidence, predicted
):
    # TODO: merge meaning prev_module and last_num1

    # write files if needed
    write_all(
        ann_qual, ann_primer, ann_filter,
        motif_dir, motif_class, module_number,
        zip_it=False, cutoff_alignments=args.cutoff_alignments
    )

    if prev_module is not None:
        # write files
        write_all(
            ann_2good, ann_1good, ann_0good,
            motif_dir, motif_class, last_num1, module_number,
            zip_it=False, cutoff_alignments=args.cutoff_alignments
        )

        # write phasing into a file
        save_phasing(
            f'{motif_dir}/phasing_{last_num1}_{module_number}.txt', phasing, supp_reads
        )

    # write the alignments
    if confidence is not None:
        # get number of precise alignments for each allele
        a1 = int(predicted[0]) if isinstance(predicted[0], int) else None
        a2 = int(predicted[1]) if isinstance(predicted[1], int) else None

        if a1 is not None and a1 > 0:
            write_alignment(
                f'{motif_dir}/alignment_{module_number}_a{a1}.fasta',
                ann_qual, module_number, a1,
                zip_it=False, cutoff_after=args.cutoff_alignments
            )
        if a2 is not None and a2 != a1 and a2 != 0:
            write_alignment(
                f'{motif_dir}/alignment_{module_number}_a{a2}.fasta',
                ann_qual, module_number, a2,
                zip_it=False, cutoff_after=args.cutoff_alignments
            )


def process_group(
    args: argparse.Namespace, df: pd.DataFrame, motif_str: str
) -> tuple[Motif, list[dict], int, int]:
    """
    Process the group as pandas Dataframe. Return motif name if processed correctly or None otherwise.
    :param args: argparse.Namespace - namespace of program arguments
    :param df: pd.DataFrame - contains information about annotated reads for a single motif to process
    :param motif_str: str - motif nomenclature
    :return: Motif, list(dict), int, int - motif, result lines, input length, length of filtered intput
    """
    motif_str = df[MOTIF_COLUMN_NAME].iloc[0]

    # build motif class
    name = None if 'name' not in df.columns or df.iloc[0]['name'] in ['None', ''] else df.iloc[0]['name']
    motif_class = Motif(motif_str, name)

    # filter/cut those with low quality
    input_len = len(df)
    # TODO: extract to function?
    if args.skip_quality_under > 0 and 'quality' in df.columns:
        filtered_df = df[df.apply(
            lambda row: has_good_quality(row, args.skip_quality_under, 1, len(motif_class.get_modules()) - 2),
            axis=1
        )]
        log_str("Kept {:4d}/{:4d} ({:5.1f}%) reads for {}".format(
            len(filtered_df), len(df), len(filtered_df) / len(df) * 100.0, motif_class.dir_name()
        ))
        df = filtered_df
    # TODO: extract to function?
    if args.cut_quality_under > 0 and 'quality' in df.columns:
        cut_df: pd.DataFrame = df.apply(
            lambda row: cut_low_quality(row, args.cut_quality_under),
            result_type="expand",  # forcing DataFrame output, instead of Series
            axis=1
        )
        kept_bases = cut_df['read'].str.len().sum()
        all_bases = df['read'].str.len().sum()
        log_str("Cut {:4d}/{:4d} ({:5.1f}%) bases for {}".format(
            (all_bases - kept_bases), all_bases, ((all_bases - kept_bases) / all_bases * 100.0),
            motif_class.dir_name()
        ))
        df = cut_df

    filtered_len = len(df)
    if filtered_len == 0:
        # TODO: maybe it would be nice to warn user?
        return motif_class, [], input_len, filtered_len

    # https://github.com/pandas-dev/pandas-stubs/issues/1001
    # create annotations from rows
    annotations: list[Annotation] = []
    for _, row in df.iterrows():
        annotations.append(Annotation(
            row['read_id'], row['mate_order'], row['read'], row['reference'],
            row['modules'], row['log_likelihood'], motif_class
        ))

    # create annotation pairs from annotations
    annotation_pairs = annotations_to_pairs(annotations)

    # deduplicate?
    if args.deduplicate:
        annotation_pairs, duplicates = remove_pcr_duplicates(annotation_pairs)

    # infer read distribution
    read_distribution = np.bincount([len(ann.read_seq) for ann in annotations], minlength=100)

    # create report for each repeating module
    result_lines: list[dict] = []
    repeating_modules = motif_class.get_repeating_modules()
    postfilter_class = PostFilter(args)
    for i, (module_number, _, _) in enumerate(repeating_modules):
        prev_module = None if i == 0 else repeating_modules[i - 1]
        file_pcolor, file_output = None, None
        if args.verbose:
            motif_dir = f'{args.output_dir}/{motif_class.dir_name()}'
            os.makedirs(motif_dir, exist_ok=True)
            file_pcolor = f'{motif_dir}/pcolor_{module_number}'
            file_output = f'{motif_dir}/allcall_{module_number}.txt'

        annotations1: list[Annotation]
        annotations1 = pairs_to_annotations_pick(annotation_pairs, module_number)
        result = too_complex_function_inferring_and_creating_reports(
            module_number=module_number,
            postfilter_class=postfilter_class, motif_dir=motif_dir,
            motif_class=motif_class, read_distribution=read_distribution,
            motif_str=motif_str, result_lines=result_lines, prev_module=prev_module,
            args=args, file_pcolor=file_pcolor, file_output=file_output, annotations1=annotations1
        )
        postfilter_counts, postfilter_counts_phasing, \
            phasing, supp_reads, confidence, predicted, result_lines, last_num1 = result

        if args.verbose:
            report(
                args, motif_dir, motif_class, module_number, last_num1, prev_module,
                postfilter_counts[0], postfilter_counts[1], postfilter_counts[2],
                postfilter_counts_phasing[0], postfilter_counts_phasing[1], postfilter_counts_phasing[2],
                phasing, supp_reads, confidence, predicted
            )

    if args.verbose:
        # generate nomenclatures for all modules:
        for i, (seq, reps) in enumerate(motif_class.get_modules()):
            # write files if needed
            if reps == 1:
                # pick annotations from pairs if needed
                annotations = pairs_to_annotations_pick(annotation_pairs, i)

                # setup post filtering - no primers, insufficient quality, ...
                qual_annot, _ = postfilter_class.get_filtered(annotations, i, both_primers=True)

                # gather and write nomenclatures
                if len(qual_annot) > 0:
                    write_histogram_nomenclature(
                        f'{motif_dir}/nomenclatures_{i}.txt', qual_annot, index_rep=i
                    )
        # try to get the overall nomenclature:
        annotations = pairs_to_annotations_pick(annotation_pairs, None)
        for module_number, _, _ in repeating_modules:
            annotations, _ = postfilter_class.get_filtered(annotations, module_number, both_primers=True)
        write_histogram_nomenclature(f'{motif_dir}/nomenclature.txt', annotations)

    # return motif name in case it was processed normally
    return motif_class, result_lines, input_len, filtered_len


def process_group_tuple(
    x: tuple[argparse.Namespace, pd.DataFrame, str]
) -> tuple[Motif, list[dict], int, int]:
    """
    Wrapper for process_group() to use in parallelization (pool.imap).
    """
    return process_group(x[0], x[1], x[2])


def generate_groups_gzipped(
    input_stream: TextIO, column_name: str = 'motif', chunk_size: int = 1000000
) -> Iterator[pd.DataFrame]:
    """
    Generate sub-parts of the input table according to "column_name".
    Able to process even large files. Gzipped version
    :param input_stream: TextIO - input stream
    :param column_name: str - column name for grouping of the table
    :param chunk_size: int - chunk size for table processing
    :return: Iterator[pd.DataFrame] - sub-parts of the input table
    """
    with gzip.GzipFile(fileobj=input_stream.buffer, mode='r') as gz_file:
        # convert to text stream
        text_stream = io.TextIOWrapper(gz_file)

        for g in generate_groups(text_stream, column_name, chunk_size):
            yield g


def generate_groups(
    input_stream: TextIO, column_name: str = 'motif', chunk_size: int = 1000000
) -> Iterator[pd.DataFrame]:
    """
    Generate sub-parts of the input table according to "column_name".
    Able to process even large files.
    :param input_stream: TextIO - input stream
    :param column_name: str - column name for grouping of the table
    :param chunk_size: int - chunk size for table processing
    :return: Iterator[pd.DataFrame] - sub-parts of the input table
    """
    # initialize reading
    current_group_data = pd.DataFrame()

    # read the output of remaSTR into annotations
    for chunk in pd.read_csv(
        input_stream, sep='\t', chunksize=chunk_size, iterator=True, quoting=csv.QUOTE_NONE
    ):

        # identify the unique groups in the chunk
        unique_groups = chunk[column_name].unique()

        # got through the groups
        for group in unique_groups:

            # filter rows for the current group from the chunk
            group_data = chunk[chunk[column_name] == group]

            # if this group is a continuation of the previous group from the last chunk
            if not current_group_data.empty and current_group_data[column_name].iloc[0] == group:
                current_group_data = pd.concat([current_group_data, group_data])
                continue  # Move to the next group in the current chunk

            # if there's data in current_group_data, process and empty it
            if not current_group_data.empty:
                yield current_group_data
                current_group_data = pd.DataFrame()  # reset

            # check if the group is at end the chunk (probably continues into next one)
            if group == unique_groups[-1]:
                current_group_data = group_data
            else:
                # process the group as normally
                yield group_data

    # process the last group
    if not current_group_data.empty:
        yield current_group_data


def consume_iterator(
    results_iterator: Iterable[tuple[Motif, list[dict], int, int]]
) -> tuple[list[Motif], pd.DataFrame, int, int]:
    """
    Consume iterator of results.
    :param results_iterator: generator - motif and its corresponding results of modules
    :return: list[Motif], pd.DataFrame, int - motifs in list and table of all results, input length
    """
    # consume iterator of results
    all_motifs: list[Motif] = []
    all_result_lines: list[dict[Any, Any]] = []
    all_input_len = 0
    all_filtered_len = 0
    for i, (motif, rls, input_l, filtered_l) in enumerate(results_iterator):
        if filtered_l > 0:
            # append data
            all_motifs.append(motif)
            all_result_lines.extend(rls)
            all_input_len += input_l
            all_filtered_len += filtered_l

        # report progress
        # if args.progress > 0 and (i + 1) % args.progress == 0:
        #     report.log_str(f'Progress: {i + 1:10d} motifs done. ({datetime.now():%Y-%m-%d %H:%M:%S})')

    df = pd.DataFrame.from_records(all_result_lines)
    df.sort_values(by=['motif_name'], kind='stable')
    return (all_motifs, df, all_input_len, all_filtered_len)


def normalize_ref_alt(ref: str, alt: str) -> tuple[str, str]:
    suffix = 0
    it = zip(reversed(ref), reversed(alt))
    for _ in range(min(len(ref), len(alt)) - 1):
        (a, b) = next(it)
        if a == b:
            suffix += 1

    return (ref[:len(ref) - suffix], alt[:len(alt) - suffix])


def make_vcf_line(
    chrom: str, pos: str, unit: str, ref_copies: str, alt_copies: str, genotype: str,
    lines: list[str]
):
    if ref_copies == alt_copies:
        return  # they are the same, there is no variant
    if "|" in alt_copies:
        return  # skip over phased variants, TODO: later

    ref_seq = unit * int(ref_copies)
    if alt_copies == "B":
        info = f"REF={ref_copies};RU={unit};BG;END={pos}"
        lines.append("{}\t{}\t{}\t{}\t{}\t{}\t{}\t{}\t{}\t{}\n".format(
            chrom, pos, ".", ref_seq, "<BG>", ".", "PASS", info, "GT", genotype
        ))
    elif alt_copies == "E":
        info = f"REF={ref_copies};RU={unit};EXP;END={pos}"
        lines.append("{}\t{}\t{}\t{}\t{}\t{}\t{}\t{}\t{}\t{}\n".format(
            chrom, pos, ".", ref_seq[0], "<EXP>", ".", "PASS", info, "GT", genotype
        ))
    else:
        alt_seq = unit * int(alt_copies)

        svlen = len(alt_seq) - len(ref_seq)
        svtype = "INS" if svlen > 0 else "DEL"
        (ref_seq, alt_seq) = normalize_ref_alt(ref_seq, alt_seq)

        info = f"REF={ref_copies};RU={unit};SVLEN={svlen};SVTYPE={svtype}"
        lines.append("{}\t{}\t{}\t{}\t{}\t{}\t{}\t{}\t{}\t{}\n".format(
            chrom, pos, ".", ref_seq, alt_seq, ".", "PASS", info, "GT", genotype
        ))


def write_vcf(df: pd.DataFrame, out: str) -> None:
    lines = []
    lines.append('##fileformat=VCFv4.1\n')
    lines.append('##ALT=<ID=BG,Description="Background">\n')
    lines.append('##ALT=<ID=EXP,Description="Expansion of unknown (large) size">\n')
    lines.append('##FILTER=<ID=PASS,Description="All filters passed">\n')
    lines.append('##FORMAT=<ID=GT,Number=1,Type=String,Description="Genotype">\n')
    lines.append('##INFO=<ID=END,Number=1,Type=Integer,Description="End position of the variant">\n')
    lines.append('##INFO=<ID=BG,Number=0,Type=Flag,Description="Background variant">\n')
    lines.append('##INFO=<ID=EXP,Number=0,Type=Flag,Description="Expansion variant">\n')
    lines.append('##INFO=<ID=REF,Number=1,Type=Integer,Description="Reference copy number">\n')
    lines.append('##INFO=<ID=RU,Number=1,Type=String,Description="Repeat unit in ref orientation">\n')
    lines.append('##INFO=<ID=SVLEN,Number=1,Type=Integer,Description="Alt length - Ref length">\n')
    lines.append('##INFO=<ID=SVTYPE,Number=1,Type=String,Description="Type of structural variant">\n')
    lines.append('#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tsample\n')

    records: list[str] = []
    for i, row in df.iterrows():
        m1 = re.match(r"([A-Z]+)\[([0-9]+)\]", row["motif_sequence"])
        if m1 is None:
            print(f"{row['motif_sequence']} returned None")
            continue
        unit, copies = m1.groups()
        allele1 = str(row["allele1"])
        allele2 = str(row["allele2"])

        if allele1 == allele2:
            make_vcf_line(row["chromosome"], row["start"], unit, copies, str(row["allele1"]), "1/1", records)
        else:
            make_vcf_line(row["chromosome"], row["start"], unit, copies, str(row["allele1"]), "1/.", records)
            make_vcf_line(row["chromosome"], row["start"], unit, copies, str(row["allele2"]), "./1", records)

    records.sort(key=lambda x: chr_and_pos(x))
    with open(f"{out}/variants.vcf", "w") as f:
        f.writelines(lines + records)


def chr_and_pos(line: str) -> tuple[int, int]:
    m1 = re.match(r"(chr[0-9XY]+)\t([0-9]+)\t.*", line)
    if m1 is None:
        raise ValueError(f"got {line}")
    chrom, pos = m1.groups()
    chrom2: int = {
        "chr1":  1,  "chr2":  2,  "chr3":  3,  "chr4":  4,  "chr5": 5,   "chr6": 6,
        "chr7":  7,  "chr8":  8,  "chr9":  9,  "chr10": 10, "chr11": 11, "chr12": 12,
        "chr13": 13, "chr14": 14, "chr15": 15, "chr16": 16, "chr17": 17, "chr18": 18,
        "chr19": 19, "chr20": 20, "chr21": 21, "chr22": 22, "chrX": 23,  "chrY": 24
    }[chrom]
    return (chrom2, int(pos))


def run_parallel(input_stream: TextIO, args: argparse.Namespace):
    groups_iterator = generate_groups(input_stream, MOTIF_COLUMN_NAME)

    stop_motif = args.start_motif + args.max_motifs if args.max_motifs is not None else None
    groups_iterator = itertools.islice(groups_iterator, args.start_motif, stop_motif)

    # create iterator of results
    all_inputs = (
        (args, motif_table, motif_table[MOTIF_COLUMN_NAME].iloc[0])
        for motif_table in groups_iterator
    )

    with multiprocessing.Pool(args.processes) as pool:
        iterator = pool.imap(process_group_tuple, all_inputs, chunksize=5)
        output = consume_iterator(iterator)

    return output


def run(input_stream: TextIO, args: argparse.Namespace):
    groups_iterator = generate_groups(input_stream, MOTIF_COLUMN_NAME)
    stop_motif = args.start_motif + args.max_motifs if args.max_motifs is not None else None
    groups_iterator = itertools.islice(groups_iterator, args.start_motif, stop_motif)

    # create iterator of results
    data = []
    for motif_table in groups_iterator:
        result = process_group(args, motif_table, "")
        data.append(result)

    output = consume_iterator(data)

    return output


def configure_logger(filename: str) -> None:
    """
    Configure logger file.
    :param filename: str - filename where to log
    :return: None
    """
    # create output directory if needed
    os.makedirs(os.path.dirname(filename), exist_ok=True)

    # configure logger
    logging.basicConfig(filename=filename, level=logging.DEBUG, format='%(asctime)s %(levelname)10s: %(message)s', filemode='w')
    logging.getLogger().setLevel(logging.INFO)


def log_str(to_log: str, stdout_too: Optional[TextIO] = sys.stderr, priority: int = logging.INFO, flush: bool = False) -> None:
    """
    Write a string to log.
    :param to_log: str - string to write to log
    :param stdout_too: bool - write the string to stdout too
    :param priority: int - logging priority
    :param flush: bool - flush this logger?
    :return: None
    """
    if stdout_too is not None:
        print(to_log, file=stdout_too)

    # delete \r and make it one-liners:
    to_log = to_log.replace('\r', '')
    to_log = to_log.replace('\n', '    ')

    # finally log it!
    logging.log(priority, to_log)

    # flush it?
    if flush:
        logging.getLogger().handlers[0].flush()


def main() -> None:
    # start_time = datetime.now()
    args = load_arguments()

    # configure_logger(f'{args.output_dir}/dante.log')
    # log_str('DANTE_remaSTR = "Da Amazing NucleoTide Exposer" (remastered)')
    # log_str(f'DANTE_remaSTR Starting : {start_time:%Y-%m-%d %H:%M:%S}')

    if args.processes > 1:
        all_motifs, rl_df, input_len, filtered_len = run_parallel(sys.stdin, args)
    else:
        all_motifs, rl_df, input_len, filtered_len = run(sys.stdin, args)

    # log_str(f'Kept {filtered_len:4d}/{input_len:4d} ({filtered_len / input_len * 100.0:5.1f}%) reads.')
    # log_str(f'Writing outputs: {datetime.now():%Y-%m-%d %H:%M:%S}')
    out_file = args.output_dir + "/variants.tsv"
    rl_df.to_csv(out_file, sep='\t')
    write_vcf(rl_df, args.output_dir)

    # generate report and output files for the whole run
    # generate report.html and alignments.html, but not fastas
    if args.verbose:
        post_filter = PostFilter(args)
        write_report(
            sorted(all_motifs), rl_df, post_filter,
            args.output_dir, args.nomenclatures
        )

    # end_time = datetime.now()
    # log_str(f'DANTE_remaSTR Stopping : {end_time:%Y-%m-%d %H:%M:%S}')
    # log_str(f'Total time of run      : {end_time - start_time}')


MOTIF_COLUMN_NAME = 'motif'
if __name__ == '__main__':
    # this is good practice so the variables do not pollute the global scope
    main()
